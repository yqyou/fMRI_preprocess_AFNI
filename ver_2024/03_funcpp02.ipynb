{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03_funcpp02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "功能像预处理的最核心部分。这一部分我们完成一下步骤\n",
    "* Despike\n",
    "* Slice-timing correction (时间层矫正)\n",
    "* Distortion correction (图像畸变矫正)\n",
    "* Motion correction (头动矫正)\n",
    "* align anat 2 epi (结构像到功能像的配准) \n",
    "* 把所有epi划到个体结构像空间\n",
    "* 把所有epi的volume数据划到surface data\n",
    "* 把所有epi的划到MNI标准空间\n",
    "* Scale (标准化数据尺度，抓换成percent signal change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Despike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================ despike =================================\n",
    "for run in runstr:\n",
    "    ! 3dDespike -NEW -nomask -prefix pb01.{subj}.r{run}.despike pb00.{subj}.r{run}.tcat+orig\n",
    "! rm pb00*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Slice-timing correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================= tshift =================================\n",
    "for run in runstr:\n",
    "    ! 3dTshift -tzero 0 -quintic -prefix pb02.{subj}.r{run}.tshift \\\n",
    "         -verbose -tpattern @{'../rawdata/SliceTiming.txt'} pb01.{subj}.r{run}.despike+orig\n",
    "\n",
    "# 删掉上一步despike的data节省空间\n",
    "! rm pb01*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Distortion correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为磁场不均匀的关系，图像会出现畸变。现在来做矫正。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先找到\n",
    "for fwd,rev in zip(fwdfiles, revfiles):\n",
    "        # create median datasets from forward and reverse time series\n",
    "        ! 3dTstat -median -prefix rm.blip.med.fwd.r{fwd} pb02.{subj}.r{fwd}.tshift+orig\n",
    "        ! 3dTstat -median -prefix rm.blip.med.rev.r{rev} pb02.{subj}.r{rev}.tshift+orig\n",
    "        # automask the median datasets \n",
    "        ! 3dAutomask -apply_prefix rm.blip.med.masked.fwd.r{fwd} rm.blip.med.fwd.r{fwd}+orig\n",
    "        ! 3dAutomask -apply_prefix rm.blip.med.masked.rev.r{rev} rm.blip.med.rev.r{rev}+orig\n",
    "        # compute the midpoint warp between the median datasets\n",
    "        ! 3dQwarp -plusminus -pmNAMES Rev.r{rev} Fwd.r{fwd}                           \\\n",
    "                -pblur 0.05 0.05 -blur -1 -1                          \\\n",
    "                -noweight -minpatch 9                                 \\\n",
    "                -noXdis -noZdis                                       \\\n",
    "                -source rm.blip.med.masked.rev.r{rev}+orig                   \\\n",
    "                -base   rm.blip.med.masked.fwd.r{fwd}+orig                   \\\n",
    "                -prefix blip_warp\n",
    "        \n",
    "        ! 3dNwarpApply -quintic -nwarp blip_warp_Fwd.r{fwd}_WARP+orig        \\\n",
    "                -source rm.blip.med.masked.fwd.r{fwd}+orig               \\\n",
    "                -prefix rm.blip.med.masked.fwd.post.r{fwd}\n",
    "\n",
    "        ! 3dNwarpApply -quintic -nwarp blip_warp_Rev.r{rev}_WARP+orig        \\\n",
    "                -source rm.blip.med.masked.rev.r{rev}+orig               \\\n",
    "                -prefix rm.blip.med.masked.rev.post.r{rev}\n",
    "        \n",
    "        # 删掉多余文件\n",
    "        ! rm blip_warp_Fwd.r{fwd}+orig* blip_warp_Rev.r{rev}+orig* \n",
    "\n",
    "        # 修改个名字以便以后的操作\n",
    "        ! 3dcopy blip_warp_Fwd.r{fwd}_WARP+orig blip_warp.r{fwd}_WARP+orig\n",
    "        ! 3dcopy blip_warp_Rev.r{rev}_WARP+orig blip_warp.r{rev}_WARP+orig\n",
    "\n",
    "        ! rm blip_warp_Fwd.r{fwd}+orig* blip_warp_Rev.r{rev}+orig* blip_warp_Fwd.r{fwd}_WARP+orig* blip_warp_Rev.r{rev}_WARP+orig* \n",
    "\n",
    "# for QC check，我们生成一个校正前和矫正后的平均EPI数据来作为distortion correction的效果证明\n",
    "! 3dMean -prefix blip_pre_fwd.epi_mean.nii.gz rm.blip.med.masked.fwd.r*\n",
    "! 3dMean -prefix blip_pre_rev.epi_mean.nii.gz rm.blip.med.masked.rev.r*\n",
    "! 3dMean -prefix blip_post_fwd.epi_mean.nii.gz rm.blip.med.masked.fwd.post.r*\n",
    "! 3dMean -prefix blip_post_rev.epi_mean.nii.gz rm.blip.med.masked.rev.post.r*\n",
    "\n",
    "# remove redundent file\n",
    "! rm rm*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这一步完成之后，可以手动打开\n",
    "* blip_pre_fwd.epi_mean.nii.gz\n",
    "* blip_pre_rev.epi_mean.nii.gz\n",
    "* blip_post_fwd.epi_mean.nii.gz\n",
    "* blip_post_rev.epi_mean.nii.gz\n",
    "\n",
    "这四个文件也记录了对侧矫正的效果，只要有矫正效果，没有什么大问题即可。\n",
    "\n",
    "然后把所有的run都做correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in runstr:\n",
    "    ! 3dNwarpApply -quintic -nwarp blip_warp.r{run}_WARP+orig      \\\n",
    "            -source pb02.{subj}.r{run}.tshift+orig         \\\n",
    "            -prefix pb03.{subj}.r{run}.blip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Motion correction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先做motion correction。但是我们并不用其结果，主要是得到mc的线性转换矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================= volreg =================================\n",
    "base = 'vr_base_min_outlier+orig' #在前面生成\n",
    "\n",
    "# align each dset to base volume, then we separate whether we want to further align epi to anat\n",
    "for run in runstr:\n",
    "    # register each volume to the base image\n",
    "    ! 3dvolreg -verbose -zpad 1 -base {base} \\\n",
    "             -1Dfile dfile.r{run}.1D \\\n",
    "             -cubic \\\n",
    "             -1Dmatrix_save mat.r{run}.vr.aff12.1D \\\n",
    "             -prefix rm.epi.nomask.r{run} pb03.{subj}.r{run}.blip+orig\n",
    "\n",
    "    # create an all-1 dataset to mask the extents of the warp\n",
    "    ! 3dcalc -overwrite -a pb03.{subj}.r{run}.blip+orig -expr 1 -prefix rm.epi.all1\n",
    "\n",
    "    # warp the all-1 dataset for extents masking\n",
    "    ! 3dAllineate -base {base} \\\n",
    "                -input rm.epi.all1+orig \\\n",
    "                -1Dmatrix_apply mat.r{run}.vr.aff12.1D \\\n",
    "                -final NN -quiet \\\n",
    "                -prefix rm.epi.1.r{run}\n",
    "\n",
    "    # make an extents intersection mask of this run across time domain\n",
    "    # this makes a mask that all volumes in this run have valid numbers\n",
    "    ! 3dTstat -min -prefix rm.epi.min.r{run} rm.epi.1.r{run}+orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算更多的头动数值，以后可以用来GLM中的regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- deal with motion parameter -------------------\n",
    "# we take dmeaned motion (6), demean motion derivative (6) and their squares (12)\n",
    "# 合并 motion params\n",
    "! cat dfile.r*.1D > dfile_rall.1D\n",
    "# 计算去均值的motion parameters (for use in regression)\n",
    "! 1d_tool.py -infile dfile_rall.1D -set_nruns {nRuns} -demean -write motion_demean.1D\n",
    "# 计算一阶导数 (just to have)\n",
    "! 1d_tool.py -infile dfile_rall.1D -set_nruns {nRuns} -derivative -demean -write motion_deriv.1D\n",
    "# calculate the square of demean and derivative of motion parameters (just to have)\n",
    "# for resting preproc, we usually have 24 motion regressor (6motion+6deriv+12 their square)\n",
    "np.savetxt('motion_demeansq.1D', np.loadtxt('motion_demean.1D')**2)\n",
    "np.savetxt('motion_derivsq.1D', np.loadtxt('motion_deriv.1D')**2)\n",
    "# create censor file motion_${subj}_censor.1D, for censoring motion\n",
    "! 1d_tool.py -infile dfile_rall.1D -set_nruns {nRuns} \\\n",
    "   -show_censor_count -censor_prev_TR \\\n",
    "   -censor_motion {motion_censor} motion_{subj}\n",
    "\n",
    "# Estimate the motion parameter after motion correction, we can check the\n",
    "# effects of MC\n",
    "! mkdir mc\n",
    "for run in runstr:\n",
    "    ! 3dvolreg -verbose -zpad 1 -base {base} \\\n",
    "             -1Dfile dfile.r{run}_pos.1D \\\n",
    "             rm.epi.nomask.r{run}+orig\n",
    "    ! rm volreg+orig*\n",
    "# make a single file of motion params\n",
    "! cat dfile.r*_pos.1D > dfile_rall_pos.1D\n",
    "\n",
    "# make figure pre mc\n",
    "dfile_pre = np.loadtxt('dfile_rall.1D')\n",
    "plot(range(dfile_pre.shape[0]), dfile_pre[:,:3], color=['C0','C1','C2'], label=['roll(IS)','pitch(RL)','yaw(AP)'])\n",
    "plt.legend();plt.xlabel('time points');plt.ylabel('mm');\n",
    "plt.savefig('rots_pre.pdf');plt.close('all')\n",
    "plot(range(dfile_pre.shape[0]), dfile_pre[:,3:], color=['C3','C4','C5'], label=['dS','dL','dP'])\n",
    "plt.legend();plt.xlabel('time points (TR)');plt.ylabel('mm');\n",
    "plt.savefig('tran_pre.pdf');plt.close('all')\n",
    "# make figure pos mc\n",
    "dfile_pos = np.loadtxt('dfile_rall_pos.1D')\n",
    "plot(range(dfile_pos.shape[0]), dfile_pos[:,:3], color=['C0','C1','C2'], label=['roll(IS)','pitch(RL)','yaw(AP)'])\n",
    "plt.legend();plt.xlabel('time points');plt.ylabel('mm');\n",
    "plt.savefig('rots_pos.pdf');plt.close('all')\n",
    "plot(range(dfile_pos.shape[0]), dfile_pos[:,3:], color=['C3','C4','C5'], label=['dS','dL','dP'])\n",
    "plt.legend();plt.xlabel('time points (TR)');plt.ylabel('mm');\n",
    "plt.savefig('tran_pos.pdf');plt.close('all')\n",
    "# move file to directory\n",
    "! mv rots*.pdf tran*.pdf dfile.r*_pos.1D dfile_r*_pos.1D mc/\n",
    "\n",
    "# note TRs that were not censored, note ktrs here is a str\n",
    "ktrs = unix_wrapper(f'1d_tool.py -infile motion_{subj}_censor.1D \\\n",
    "                       -show_trs_uncensored encoded', wantreturn=True, verbose=0)\n",
    "\n",
    "# ----------------------------------------\n",
    "# create the extents mask: mask_epi_extents+orig and apply the task\n",
    "# (this is a mask of voxels that have valid data at every TR,\n",
    "# there might be some pixel out of extents during mc)\n",
    "! 3dMean -datum short -prefix rm.epi.mean rm.epi.min.r*.HEAD\n",
    "! 3dcalc -a rm.epi.mean+orig -expr \"step(a-0.999)\" -prefix mask_epi_extents\n",
    "# and apply the extents mask to the EPI data\n",
    "# (delete any time series with missing data)\n",
    "for run in runstr:\n",
    "    ! 3dcalc -a rm.epi.nomask.r{run}+orig -b mask_epi_extents+orig \\\n",
    "           -expr \"a*b\" -prefix pb04.{subj}.r{run}.volreg\n",
    "! rm -f rm.*  # rm.epi.nomask are big files, remove them\n",
    "! rm -f {base}* \n",
    "\n",
    "# calculate a mean epi volume for next step anat epi registration\n",
    "! 3dMean -prefix rm.epi_mean.nii.gz pb04.{subj}.r*.volreg+orig.HEAD\n",
    "! 3dTstat -prefix epi_mean.nii.gz rm.epi_mean.nii.gz\n",
    "! rm rm* mask_epi_extents+orig*\n",
    "\n",
    "# 删掉上一步distortion correction的数据，节省空间\n",
    "! rm pb03*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. anat2epi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这一步非常重要，是前面处理好的功能像和结构像进行配准，配准的结果一定要手动检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先把用来配准的epi像make a copy\n",
    "! 3dcopy epi_mean.nii.gz epi_mean_tmp.nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 关键步骤。我们是把结构像配准到功能像，但是我们得到的转换矩阵是从相反的，功能像到结构像，这个矩阵可以后面用来转化epi数据\n",
    "! align_epi_anat.py -anat2epi \\\n",
    "    -anat {t1ss} -anat_has_skull no \\\n",
    "    -suffix _al_junk \\\n",
    "    -epi epi_mean_tmp.nii.gz -epi_base 0 \\\n",
    "    -epi_strip 3dAutomask -giant_move \\\n",
    "    -volreg off -tshift off\n",
    "\n",
    "# 生成nifti文件，方便我们在fsleyes上面查看配准效果\n",
    "! 3dcopy {t1ss.pstem}_al_junk+orig {t1ss.pstem}_al_junk.nii.gz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完成上面一步之后，要打开afni仔细检查配准的结果，其中underlay选择CN003_SurfVol_al_junk+orig, overlay选择epi_mean_tmp+orig。然后检查两者是否一致。如果不匹配，则需要重新进行上面的过程，在开始之前，需要先删除上面产生的文件。可以做\n",
    "! rm {subj}_SurfVol_al* {subj}_SurfVol_ns*\n",
    "确认配准没有问题之后，进行下一步操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# note that we align anat 2 epi, however, this xfm is from epi space to anat space\n",
    "# note that this xfm is compatible with LPS+ space, which is the default space in AFNI\n",
    "! mv {t1ss.pstem}_al_junk_mat.aff12.1D mat.anat2epi.aff12.1D\n",
    "\n",
    "#######去头皮后的结构像就是t1ss({subj}_SurfVol_SS.nii), 不需要再生成\n",
    "# create an skull-striped anat_final dataset, aligned with stats\n",
    "#! 3dcopy {t1ss.pstem}_ns+orig anat_final.{subj}.nii.gz\n",
    "#! rm {t1ss.pstem}_ns+orig*\n",
    "! 3dcopy {t1ss} anat_final.{subj}.nii.gz\n",
    "########\n",
    "\n",
    "# rewrite the name of aligned anat\n",
    "! 3dcopy {t1ss.pstem}_al_junk+orig anat2epi.{subj}.nii.gz\n",
    "! rm {t1ss.pstem}_al_junk+orig*\n",
    "\n",
    "# Invert xfm\n",
    "! cat_matvec -ONELINE mat.anat2epi.aff12.1D -I > mat.epi2anat.aff12.1D\n",
    "\n",
    "# warp the volreg base EPI dataset back to anat to make a final version\n",
    "! 3dAllineate -base anat_final.{subj}.nii.gz \\\n",
    "            -input epi_mean.nii.gz \\\n",
    "            -1Dmatrix_apply mat.epi2anat.aff12.1D \\\n",
    "            -prefix epi2anat.{subj}.nii.gz\n",
    "\n",
    "# Record final registration costs\n",
    "! 3dAllineate -base epi2anat.{subj}.nii.gz -allcostX -input anat_final.{subj}.nii.gz > out.allcostX.txt\n",
    "\n",
    "# Take the snapshots to show the quality of alignment\n",
    "! @snapshot_volreg epi2anat.{subj}.nii.gz anat_final.{subj}.nii.gz\n",
    "! @snapshot_volreg anat_final.{subj}.nii.gz epi2anat.{subj}.nii.gz\n",
    "! @snapshot_volreg anat2epi.{subj}.nii.gz epi_mean.nii.gz\n",
    "! @snapshot_volreg epi_mean.nii.gz anat2epi.{subj}.nii.gz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. epi to individual anat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们有了epi到anat的配准，然后我们就可以把所有的epi的文件划到t1的空间。注意，这一步并不是从motion correction之后的文件，也就是pb03.CN003.r0X.volreg+orig。我们要从早distrotion correction之前的文件，把从DC-MC-epi2anat这三个转换一次性的做完"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================= epi to individual anat =================================\n",
    "# resolution=2.5  # 改到最开始的参数设置\n",
    "# ======== Transform epi to match anat, add by RZ ===============\n",
    "# In this step we need to concatenate Distortion(opt)+motion+affine transformations\n",
    "# align each dset to base volume, then we separate whether we want to further align epi to anat\n",
    "for run in runstr:\n",
    "    # concatenate MC+aff transforms\n",
    "    ! cat_matvec -ONELINE mat.anat2epi.aff12.1D -I mat.r{run}.vr.aff12.1D > mat.r{run}.warp.aff12.1D\n",
    "\n",
    "    # we apply distortion correction + motion correction + anat2epi transformation\n",
    "    cmd = f'3dNwarpApply -quintic -nwarp \"mat.r{run}.warp.aff12.1D blip_warp.r{run}_WARP+orig\" \\\n",
    "            -master {t1ss} -dxyz {resolution} \\\n",
    "            -source pb02.{subj}.r{run}.tshift+orig         \\\n",
    "            -prefix rm.epi.nomask.r{run}'\n",
    "    unix_wrapper(cmd)\n",
    "\n",
    "    # create an all-1 dataset to mask the extents of the warp\n",
    "    ! 3dcalc -overwrite -a pb02.{subj}.r{run}.tshift+orig -expr 1 -prefix rm.epi.all1\n",
    "\n",
    "    # we apply distortion correction + motion correction + anat2epi transformation\n",
    "    cmd = f'3dNwarpApply -quintic -nwarp \"mat.r{run}.warp.aff12.1D blip_warp.r{run}_WARP+orig\" \\\n",
    "            -master {t1ss} -dxyz {resolution} \\\n",
    "            -ainterp NN -quiet \\\n",
    "            -source rm.epi.all1+orig \\\n",
    "            -prefix rm.epi.1.r{run}'\n",
    "    unix_wrapper(cmd)\n",
    "\n",
    "    # make an extents intersection mask of this run across time domain\n",
    "    # this makes a mask that all volumes in this run have valid numbers\n",
    "    ! 3dTstat -min -prefix rm.epi.min.r{run} rm.epi.1.r{run}+orig\n",
    "    # below file is big, should be removed\n",
    "    ! rm rm.epi.1.r{run}+orig*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "做了变化之后，也要处理一下mask的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------------------\n",
    "# create the extents mask: mask_epi_extents+orig\n",
    "# (this is a mask of voxels that have valid data at every TR,\n",
    "# there might be some pixel out of extents during mc)\n",
    "! 3dMean -datum short -prefix rm.epi.mean rm.epi.min.r*.HEAD\n",
    "# and apply the extents mask to the EPI data\n",
    "! 3dcalc -a rm.epi.mean+orig -expr \"step(a-0.999)\" -prefix mask_epi_extents\n",
    "\n",
    "# 去掉mask之外的voxel的数据\n",
    "for run in runstr:\n",
    "    ! 3dcalc -a rm.epi.nomask.r{run}+orig -b mask_epi_extents+orig \\\n",
    "           -expr \"a*b\" -prefix pb05.{subj}.r{run}.al2anat\n",
    "    # save to nifti format seems to reduce file size\n",
    "\n",
    "# rm.epi.nomask are big files, remove them\n",
    "! rm rm.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7. epi volume 2 surface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上一步我们已经把epi数据划到了和个体的结构像一个空间。很多时候我们需要做基于surface的数据分析。我们进一步把三维的epi数据插值划到surface上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ================================= epi volume to surface =================================\n",
    "surface_dir = FREESURFER_HOME+f'/subjects/{subj}/SUMA'\n",
    "# map volume data to the surface of each hemisphere\n",
    "for hemi in ['lh', 'rh']:\n",
    "    for  run in runstr:\n",
    "        ! 3dVol2Surf -spec {surface_dir}/std.141.{subj}_{hemi}.spec   \\\n",
    "                   -sv {subj}_SurfVol_2std.nii           \\\n",
    "                   -surf_A smoothwm                            \\\n",
    "                   -surf_B pial                                \\\n",
    "                   -f_index nodes                              \\\n",
    "                   -f_steps 10                                 \\\n",
    "                   -map_func ave                               \\\n",
    "                   -oob_value 0                                \\\n",
    "                   -grid_parent pb05.{subj}.r{run}.al2anat+orig   \\\n",
    "                   -out_niml pb05.{subj}.{hemi}.r{run}.surf.niml.dset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8. epi to MNI anat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ================================= epi to MNI anat =================================\n",
    "# ======== Transform epi to match anat, add by RZ ===============\n",
    "# In this step we need to concatenate Distortion(opt)+motion+affine transformations\n",
    "# align each dset to base volume, then we separate whether we want to further align epi to anat\n",
    "for run in runstr:\n",
    "\n",
    "    # we apply distortion correction + motion correction + anat2epi + nonlinear warp to MNI transformation\n",
    "    # 注意我们这里是相反的顺序来concatenate的\n",
    "    cmd = f'3dNwarpApply -quintic -nwarp \"anatQQ.{subj}_WARP.nii anatQQ.{subj}.aff12.1D mat.r{run}.warp.aff12.1D blip_warp.r{run}_WARP+orig\" \\\n",
    "            -master MNI152_2009_template_SSW.nii.gz \\\n",
    "            -dxyz {resolution} \\\n",
    "            -source pb02.{subj}.r{run}.tshift+orig \\\n",
    "            -prefix rm.epi.nomask.r{run}'\n",
    "    unix_wrapper(cmd)\n",
    "\n",
    "    # create an all-1 dataset to mask the extents of the warp\n",
    "    ! 3dcalc -overwrite -a pb02.{subj}.r{run}.tshift+orig -expr 1 -prefix rm.epi.all1\n",
    "\n",
    "    # we apply distortion correction + motion correction + anat2epi transformation\n",
    "    cmd = f'3dNwarpApply -quintic -nwarp \"anatQQ.{subj}_WARP.nii anatQQ.{subj}.aff12.1D mat.r{run}.warp.aff12.1D blip_warp.r{run}_WARP+orig\" \\\n",
    "            -master MNI152_2009_template_SSW.nii.gz \\\n",
    "            -dxyz {resolution} \\\n",
    "            -source rm.epi.all1+orig         \\\n",
    "            -ainterp NN -quiet \\\n",
    "            -prefix rm.epi.1.r{run}'\n",
    "    unix_wrapper(cmd)\n",
    "\n",
    "    # make an extents intersection mask of this run across time domain\n",
    "    # this makes a mask that all volumes in this run have valid numbers\n",
    "    ! 3dTstat -min -prefix rm.epi.min.r{run} rm.epi.1.r{run}+tlrc\n",
    "    # below file is big, should be removed\n",
    "    ! rm rm.epi.1.r{run}+tlrc*      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "做了变化之后，也要处理一下mask的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# create the extents mask: mask_epi_extents+orig\n",
    "# (this is a mask of voxels that have valid data at every TR,\n",
    "# there might be some pixel out of extents during mc)\n",
    "! 3dMean -datum short -prefix rm.epi.mean rm.epi.min.r*.HEAD\n",
    "! 3dcalc -a rm.epi.mean+tlrc -expr \"step(a-0.999)\" -prefix mask_epi_2mni_extents\n",
    "\n",
    "# 去掉mask之外的voxel的数据\n",
    "for run in runstr:\n",
    "    ! 3dcalc -a rm.epi.nomask.r{run}+tlrc -b mask_epi_2mni_extents+tlrc \\\n",
    "           -expr \"a*b\" -prefix pb06.{subj}.r{run}.al2mni\n",
    "    # save to nifti format seems to reduce file size\n",
    "\n",
    "# rm.epi.nomask are big files, remove them\n",
    "! rm rm.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 补充步骤，用于进行smooth操作，  2022.7.3添加\n",
    "# 目的是对上一步step8所生成的pb06进行smooth   生成pb06s\n",
    "# 再对上上一步step7所生成的pb05***surf.niml文件进行smooth  生成pb05s*rh  和 pb05s*lh\n",
    "# 再对上上一步step7所生成的pb05.subj.r0*.al2anat+orig文件进行smooth  生成pb05s*.subj.r0*.blur+al2anat+orig\n",
    "\n",
    "for run in runstr:\n",
    "    ! 3dmerge -1blur_fwhm 4.0 -doall -prefix pb06s.{subj}.r{run}.blur+al2mni+tlrc \\\n",
    "        pb06.{subj}.r{run}.al2mni+tlrc\n",
    "\n",
    "for run in runstr:\n",
    "    ! 3dmerge -1blur_fwhm 4.0 -doall -prefix pb05s.{subj}.lh.r{run}.blur.surf.niml.dset \\\n",
    "        pb05.{subj}.lh.r{run}.surf.niml.dset\n",
    "\n",
    "for run in runstr:\n",
    "    ! 3dmerge -1blur_fwhm 4.0 -doall -prefix pb05s.{subj}.rh.r{run}.blur.surf.niml.dset \\\n",
    "        pb05.{subj}.rh.r{run}.surf.niml.dset\n",
    "\n",
    "#以下代码可以不用跑\n",
    "for run in runstr:\n",
    "    ! 3dmerge -1blur_fwhm 4.0 -doall -prefix pb05s.{subj}.r{run}.blur+al2anat+orig \\\n",
    "        pb05.{subj}.r{run}.al2anat+orig\n",
    "\n",
    "\n",
    "\n",
    "'''  \n",
    "#afni官网上的对于surface数据进行smooth的代码\n",
    "\n",
    "foreach hemi ( lh rh )\n",
    "    foreach run ( $runs )\n",
    "        # to save time, estimate blur parameters only once\n",
    "        if ( ! -f surf.smooth.params.1D ) then\n",
    "            SurfSmooth -spec $surface_dir/std.60.FT_${hemi}.spec         \\\n",
    "                       -surf_A smoothwm                                  \\\n",
    "                       -input pb03.$subj.$hemi.r$run.surf.niml.dset      \\\n",
    "                       -met HEAT_07                                      \\\n",
    "                       -target_fwhm 6.0                                  \\\n",
    "                       -blurmaster pb03.$subj.$hemi.r$run.surf.niml.dset \\\n",
    "                       -detrend_master                                   \\\n",
    "                       -output pb04.$subj.$hemi.r$run.blur.niml.dset     \\\n",
    "                       | tee surf.smooth.params.1D\n",
    "        else\n",
    "            set params = `1dcat surf.smooth.params.1D`\n",
    "            SurfSmooth -spec $surface_dir/std.60.FT_${hemi}.spec         \\\n",
    "                       -surf_A smoothwm                                  \\\n",
    "                       -input pb03.$subj.$hemi.r$run.surf.niml.dset      \\\n",
    "                       -met HEAT_07                                      \\\n",
    "                       -Niter $params[1]                                 \\\n",
    "                       -sigma $params[2]                                 \\\n",
    "                       -output pb04.$subj.$hemi.r$run.blur.niml.dset\n",
    "        endif\n",
    "    end\n",
    "end\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9. 创造一个所有epi和mni模板共有的mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== Mask =================================\n",
    "# Create 'full_mask' dataset (union mask)\n",
    "for run in runstr:\n",
    "    ! 3dAutomask -prefix rm.mask_r{run}.nii.gz pb06.{subj}.r{run}.al2mni+tlrc\n",
    "\n",
    "# 创造一个所有功能像的run合起来的mask\n",
    "! 3dmask_tool -inputs rm.mask_r*.nii.gz -union -prefix full_mask.{subj}.nii.gz\n",
    "! rm rm.mask*\n",
    "\n",
    "# ---- create subject anatomy mask, mask_anat.$subj+orig ----\n",
    "#      (resampled from aligned anat)\n",
    "# 把功能像resample到上面mask的分辨率\n",
    "! 3dresample -master full_mask.{subj}.nii.gz -input \\\n",
    "           MNI152_2009_template_SSW.nii.gz -prefix rm.resam.anat.nii.gz\n",
    "# convert to binary anat mask; fill gaps and holes\n",
    "! 3dmask_tool -dilate_input 5 -5 -fill_holes -input rm.resam.anat.nii.gz \\\n",
    "            -prefix mask_anat.{subj}.nii.gz\n",
    "\n",
    "# 结合功能像和结构像的mask\n",
    "# compute tighter EPI mask by intersecting with anat mask\n",
    "! 3dmask_tool -input full_mask.{subj}.nii.gz mask_anat.{subj}.nii.gz \\\n",
    "            -inter -prefix mask_epi_anat.{subj}.nii.gz\n",
    "# note Dice coefficient of masks, as well\n",
    "! 3ddot -dodice full_mask.{subj}.nii.gz mask_anat.{subj}.nii.gz > out.mask_ae_dice.txt\n",
    "\n",
    "# 删掉多余文件\n",
    "! rm rm*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10. scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原始EPI图像的数据可能很大，从几百到4000不等。但是我们一般不考虑这个绝对强度，考虑的是信号增长的比例。所以把数据scale一下, 让所有的voxel的时间序列均值为100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意！！！这个cell的代码是对pb06以及pb05 进行scale重置 也就是未经smooth的数据\n",
    "# scale each voxel time series to have a mean of 100\n",
    "# (be sure no negatives creep in)\n",
    "# (subject to a range of [0,200])\n",
    "# scale volume data\n",
    "\n",
    "for run in runstr:\n",
    "    ! 3dTstat -prefix rm.mean_r{run} pb06.{subj}.r{run}.al2mni+tlrc\n",
    "    ! 3dcalc -a pb06.{subj}.r{run}.al2mni+tlrc -b rm.mean_r{run}+tlrc \\\n",
    "           -c mask_epi_2mni_extents+tlrc \\\n",
    "           -expr \"c * min(200, a/b*100)*step(a)*step(b)\" \\\n",
    "           -prefix pb07.{subj}.r{run}.scale\n",
    "\n",
    "# combine all datasets into one\n",
    "! 3dTcat -prefix all_runs.{subj}.nii.gz pb07.{subj}.r*.scale+tlrc*\n",
    "# remove redundant file\n",
    "! rm rm.mean*\n",
    "\n",
    "# 再scale surface data\n",
    "for hemi in ['lh', 'rh']:\n",
    "    for run in runstr:\n",
    "       ! 3dTstat -prefix rm.{hemi}.mean_r{run}.niml.dset    \\\n",
    "            pb05.{subj}.{hemi}.r{run}.surf.niml.dset\n",
    "       ! 3dcalc -a pb05.{subj}.{hemi}.r{run}.surf.niml.dset  \\\n",
    "               -b rm.{hemi}.mean_r{run}.niml.dset          \\\n",
    "               -expr 'min(200, a/b*100)*step(a)*step(b)' \\\n",
    "               -prefix pb07.{subj}.{hemi}.r{run}.scale.niml.dset\n",
    "\n",
    "# remove redundant file\n",
    "! rm rm.*mean* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意！！！这个cell的代码是对pb06s 以及pb05s 进行scale重置 也就是经过了smooth的数据\n",
    "# 生成pb07s*.scale  \n",
    "# 这个文件被整合成all_runs_with_smooth\n",
    "# 生成pb07s*.scale.niml.dset\n",
    "\n",
    "# scale volume data\n",
    "for run in runstr:\n",
    "    ! 3dTstat -prefix rm.mean_r{run} pb06s.{subj}.r{run}.blur+al2mni+tlrc\n",
    "    ! 3dcalc -a pb06s.{subj}.r{run}.blur+al2mni+tlrc -b rm.mean_r{run}+tlrc \\\n",
    "           -c mask_epi_2mni_extents+tlrc \\\n",
    "           -expr \"c * min(200, a/b*100)*step(a)*step(b)\" \\\n",
    "           -prefix pb07s.{subj}.r{run}.scale\n",
    "\n",
    "# combine all datasets into one\n",
    "! 3dTcat -prefix all_runs_with_smooth.{subj}.nii.gz pb07s.{subj}.r*.scale+tlrc*\n",
    "# remove redundant file\n",
    "! rm rm.mean*\n",
    "\n",
    "# 再scale surface data\n",
    "for hemi in ['lh', 'rh']:\n",
    "    for run in runstr:\n",
    "       ! 3dTstat -prefix rm.{hemi}.mean_r{run}.niml.dset    \\\n",
    "            pb05s.{subj}.{hemi}.r{run}.blur.surf.niml.dset\n",
    "       ! 3dcalc -a pb05s.{subj}.{hemi}.r{run}.blur.surf.niml.dset  \\\n",
    "               -b rm.{hemi}.mean_r{run}.niml.dset          \\\n",
    "               -expr 'min(200, a/b*100)*step(a)*step(b)' \\\n",
    "               -prefix pb07s.{subj}.{hemi}.r{run}.scale.niml.dset\n",
    "# remove redundant file\n",
    "! rm rm.*mean* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到这一步，基本上最主要的预处理就完结了。下一步可以进一步针对surface数据跑GLM，因为afni的surface都是在freesurfer的模板上对其且标准化的，所以surface数据可以直接跑group analysis。也可以在已经划到MNI space上的volume数据跑GLM。以后在volume上跑GLM的结果可以直接用MNI152的T1像来可视化"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43945f80469130c119fb960c4295ae331e7fb51022383025e24ae21a08d5f82b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
