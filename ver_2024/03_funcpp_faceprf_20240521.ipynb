{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 funcpp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### funcpp0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RZutilpy.system import Path, unix_wrapper, gettimestr, makedirs\n",
    "from RZutilpy.rzio import matchfiles\n",
    "from RZutilpy.mri import findminoutlier\n",
    "from RZutilpy.figure import plot\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ========================== Set parameter ============================\n",
    "# subject, session, run\n",
    "subj = 'CN040'\n",
    "session = '20230619_CN040_session2/'\n",
    "runlist = ['201','301','401','601','701','901','1001','1101','1301','1401','501','801','1201']\n",
    "#runlist = ['301','401','501','701','801','1001','1101','1201','1401','1501','601','901','1301']\n",
    "#runlist = ['201','301','401','601','701','1101','1201','1301','1501','1601','501','801','1401']\n",
    "# =====================================================================\n",
    "\n",
    "\n",
    "foldpath = '/home/data/rawdata/facePRF/'+subj+'_faceprf/'+session\n",
    "os.chdir(foldpath+'rawdata/')\n",
    "\n",
    "# a list of functional NIFTI files\n",
    "files = []\n",
    "for r in runlist:\n",
    "    files.append(matchfiles(foldpath+'rawdata/'+'*_'+r+'_task*.nii'))\n",
    "\n",
    "\n",
    "# t1 file\n",
    "t1 = Path(f'/home/software/freesurfer/7.3.2/subjects/{subj}/SUMA/{subj}_SurfVol.nii') # 256x256x256\n",
    "t1ssmask = Path(f'/home/data/rawdata/facePRF/{subj}_faceprf/20230607_CN040_session0/anatpp/T1_SSMask.nii')\n",
    "t1ss = subj+'_SurfVol_SS.nii'\n",
    "\n",
    "# output directory, if exists, we exit\n",
    "output_dir = Path(foldpath+'/funcpp/')\n",
    "\n",
    "# number of tr to discard\n",
    "tr_discard = 0  # number of tr to discard\n",
    "\n",
    "# motion censor limit\n",
    "motion_censor = 0.3  # threshold for motion censoring, default:(0.3)\n",
    "\n",
    "# extra option for align_epi_anat.py\n",
    "align_opt = ['-giant_move']\n",
    "\n",
    "# epi2anat(individual)\n",
    "resolution = 2.5\n",
    "\n",
    "# grid at each axies of {subj}.SurfVol.nii\n",
    "grid_RL = 256\n",
    "grid_AP = 256\n",
    "grid_IS = 256\n",
    "\n",
    "# some calculation\n",
    "fwdnum = 10\n",
    "revnum = 3\n",
    "nRuns = len(files)\n",
    "runstr = [f'{i:02d}AP' for i in range(1,fwdnum+1)] + [f'{i:03d}PA' for i in range(1,revnum+1)]\n",
    "motion_censor = 0.3 if motion_censor is None else motion_censor\n",
    "\n",
    "fwdfiles = ['01AP', '02AP','03AP', '04AP', '05AP', '06AP', '07AP', '08AP', '09AP', '10AP'] # 这里需要手动run的顺序，用来做配对distortion correction\n",
    "revfiles = ['001PA','001PA','001PA', '002PA','002PA', '003PA','003PA','003PA','003PA','003PA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== deal with some input parameters =======================\n",
    "# Show some diagnostic information\n",
    "# check file exists\n",
    "for i in files:\n",
    "    assert Path(i).exists(), f'{i} does not exist!'\n",
    "\n",
    "t1 = Path(t1)\n",
    "assert t1.exists(), 'T1 file does not exist!'\n",
    "\n",
    "# generate slice timing file\n",
    "if not Path('SliceTiming.txt').exists():\n",
    "    import json \n",
    "    #with open(f'{Path(files[0])}.json') as f:\n",
    "    with open(f'{files[0][:-4]}.json') as f:\n",
    "        jsoninfo = json.load(f)\n",
    "    np.savetxt('SliceTiming.txt', jsoninfo['SliceTiming'])\n",
    "    print('generate SliceTiming.txt!')\n",
    "    del jsoninfo\n",
    "\n",
    "# 整理forward和reverse的文件，如果两者数量不相等，我们自动补齐缺数量\n",
    "if len(fwdfiles)!=len(revfiles):\n",
    "    if len(fwdfiles)>len(revfiles):\n",
    "        nPair = len(fwdfiles)\n",
    "        revfiles = revfiles + [revfiles[-1]]*(nPair-len(revfiles))\n",
    "    else:\n",
    "        nPair = len(revfiles)\n",
    "        fwdfiles = fwdfiles + [fwdfiles[-1]]*(nPair-len(fwdfiles))\n",
    "\n",
    "# print out some diagnoistic\n",
    "print(f'\\nt1 file is: \\n{t1}')\n",
    "print(f'functional files are: \\n')\n",
    "[print(f'{i}') for i in files]\n",
    "print(f'\\nforward files are: {fwdfiles} \\n')\n",
    "print(f'reverse files are: {revfiles} \\n')\n",
    "print(f'\\nslice timing file is: \\nSliceTiming.txt')\n",
    "\n",
    "\n",
    "\n",
    "start_time = gettimestr(\"full\")\n",
    "print(f'\\n=============== Preprocessing started: {start_time} ================\\n')\n",
    "# change shell to tcsh, afni default shell is tcsh\n",
    "orig_shell = os.environ['SHELL']\n",
    "os.environ['SHELL']='/usr/bin/tcsh'\n",
    "cwd = Path.cwd() # record current directory, we will go back\n",
    "\n",
    "# verify that the results directory does not yet exist\n",
    "output_dir = Path(output_dir)\n",
    "assert not output_dir.exists(), f'output dir {output_dir} already exists'\n",
    "makedirs(output_dir)\n",
    "# enter the results directory (can begin processing data)\n",
    "os.chdir(output_dir)\n",
    "# copy anatomy to results dir\n",
    "! 3dcopy {t1} {t1.pstem}\n",
    "t1 = Path(f'{t1.pstem}+orig')  # switch t1 to the new location\n",
    "\n",
    "# copy nonlinear-warping MNI files to this folder\n",
    "FREESURFER_HOME = os.getenv('FREESURFER_HOME')\n",
    "AFNI_HOME = os.getenv('AFNIDIR')\n",
    "! cp {FREESURFER_HOME}/subjects/{subj}/mni/anatQQ.{subj}_WARP.nii ./\n",
    "! cp {FREESURFER_HOME}/subjects/{subj}/mni/anatQQ.{subj}.aff12.1D ./\n",
    "! cp {AFNI_HOME}/MNI152_2009_template_SSW.nii.gz ./\n",
    "! cp {t1ssmask} T1_SSMask.{subj}.nii\n",
    "! 3dcopy {t1} {subj}_SurfVol.nii\n",
    "\n",
    "\n",
    "# 根据T1_SSMask.{subj}.nii得到剥头皮后的T1，但首先要把朝向和grid对齐\n",
    "! 3dresample -orient LPI -prefix {subj}_SurfVol_2std.nii -input {subj}_SurfVol.nii\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "# 利用3dZeropad将mask和T1像的grid对齐，否则无法把mask和T1像相乘：\n",
    "# 例如在这个例子中{subj}_SurfVol.nii是256 x 256 x 256，而T1_SSMask.{subj}.nii是240 x 256 x 256。所以这里在T1_SSMask.{subj}.nii的第一个轴（R-L）修改为256。相当于在左右两侧分别加了8.\n",
    "# 3个轴： -RL -AP -IS，请根据具体情况修改此行代码\n",
    "! 3dZeropad -RL {grid_RL} -prefix T1_SSMask_grid.{subj}.nii  T1_SSMask.{subj}.nii\n",
    "! 3dZeropad -AP {grid_AP} -prefix T1_SSMask_grid.{subj}.nii  T1_SSMask_grid.{subj}.nii -overwrite\n",
    "! 3dZeropad -IS {grid_IS} -prefix T1_SSMask_grid.{subj}.nii  T1_SSMask_grid.{subj}.nii -overwrite\n",
    "#-------------------------------------------------------------\n",
    "\n",
    "! 3dcalc -a {subj}_SurfVol_2std.nii -b T1_SSMask_grid.{subj}.nii -expr 'a*step(b)' -prefix {t1ss}\n",
    "t1ss = Path(t1ss)  # switch t1 to the new location\n",
    "\n",
    "\n",
    "\n",
    "# ============================ auto block: tcat ============================\n",
    "# apply 3dTcat to copy input dsets to results dir,\n",
    "# while might want removing the first TRs\n",
    "\n",
    "for file, run in zip(files, runstr):\n",
    "    cmd=f'3dTcat -prefix pb00.{subj}.r{run}.tcat {file}[{tr_discard}..$]'\n",
    "    unix_wrapper(cmd)\n",
    "\n",
    "# ===========================reorient =========================\n",
    "# 利用3dresample把朝向划到标准朝向LPI\n",
    "# 需要AP,PA一起做\n",
    "for run in runstr:\n",
    "    ! 3dresample -orient LPI -prefix pb00.{subj}.r{run}.tcat+orig -input pb00.{subj}.r{run}.tcat+orig -overwrite\n",
    "\n",
    "\n",
    "# ============================auto block: giant_move, added by RZ ===========================\n",
    "for run in runstr:\n",
    "    # 把图像的中点划到统一显示空间的中点\n",
    "    ! 3drefit -deoblique -xorigin cen -yorigin cen -zorigin cen pb00.{subj}.r{run}.tcat+orig\n",
    "    # 然后把function数据和 t1ss文件的重心移动到一致，这样有利于进行配准\n",
    "    ! @Align_Centers -cm -no_cp -base {t1ss} -dset pb00.{subj}.r{run}.tcat+orig\n",
    "\n",
    "! rm *_shft.1D\n",
    "\n",
    "\n",
    "findminoutlier(f'pb00.{subj}.r*AP.tcat+orig.HEAD', output_dir)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### funcpp02\n",
    "\n",
    "功能像预处理的最核心部分。这一部分我们完成一下步骤\n",
    "* Despike\n",
    "* Slice-timing correction (时间层矫正)\n",
    "* Distortion correction (图像畸变矫正)\n",
    "* Motion correction (头动矫正)\n",
    "* align anat 2 epi (结构像到功能像的配准) \n",
    "* 把所有epi划到个体结构像空间\n",
    "* 把所有epi的volume数据划到surface data\n",
    "* 把所有epi的划到MNI标准空间\n",
    "* Scale (标准化数据尺度，转换成percent signal change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================ despike =================================\n",
    "for run in runstr:\n",
    "    ! 3dDespike -NEW -nomask -prefix pb01.{subj}.r{run}.despike pb00.{subj}.r{run}.tcat+orig\n",
    "#! rm pb00*\n",
    "\n",
    "\n",
    "# ================================= tshift =================================\n",
    "for run in runstr:\n",
    "    ! 3dTshift -tzero 0 -quintic -prefix pb02.{subj}.r{run}.tshift \\\n",
    "         -verbose -tpattern @{'../rawdata/SliceTiming.txt'} pb01.{subj}.r{run}.despike+orig\n",
    "\n",
    "# 删掉上一步despike的data节省空间\n",
    "! rm pb01*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================= distortion =================================\n",
    "# 首先找到\n",
    "for fwd,rev in zip(fwdfiles, revfiles):\n",
    "        # create median datasets from forward and reverse time series\n",
    "        ! 3dTstat -median -prefix rm.blip.med.fwd.r{fwd} pb02.{subj}.r{fwd}.tshift+orig\n",
    "        ! 3dTstat -median -prefix rm.blip.med.rev.r{rev} pb02.{subj}.r{rev}.tshift+orig\n",
    "        # automask the median datasets \n",
    "        ! 3dAutomask -apply_prefix rm.blip.med.masked.fwd.r{fwd} rm.blip.med.fwd.r{fwd}+orig\n",
    "        ! 3dAutomask -apply_prefix rm.blip.med.masked.rev.r{rev} rm.blip.med.rev.r{rev}+orig\n",
    "        # compute the midpoint warp between the median datasets\n",
    "        ! 3dQwarp -plusminus -pmNAMES Rev.r{rev} Fwd.r{fwd}                           \\\n",
    "                -pblur 0.05 0.05 -blur -1 -1                          \\\n",
    "                -noweight -minpatch 9                                 \\\n",
    "                -noXdis -noZdis                                       \\\n",
    "                -source rm.blip.med.masked.rev.r{rev}+orig                   \\\n",
    "                -base   rm.blip.med.masked.fwd.r{fwd}+orig                   \\\n",
    "                -prefix blip_warp\n",
    "        \n",
    "        ! 3dNwarpApply -quintic -nwarp blip_warp_Fwd.r{fwd}_WARP+orig        \\\n",
    "                -source rm.blip.med.masked.fwd.r{fwd}+orig               \\\n",
    "                -prefix rm.blip.med.masked.fwd.post.r{fwd}\n",
    "\n",
    "        ! 3dNwarpApply -quintic -nwarp blip_warp_Rev.r{rev}_WARP+orig        \\\n",
    "                -source rm.blip.med.masked.rev.r{rev}+orig               \\\n",
    "                -prefix rm.blip.med.masked.rev.post.r{rev}\n",
    "        \n",
    "        # 删掉多余文件\n",
    "        ! rm blip_warp_Fwd.r{fwd}+orig* blip_warp_Rev.r{rev}+orig* \n",
    "\n",
    "        # 修改个名字以便以后的操作\n",
    "        ! 3dcopy blip_warp_Fwd.r{fwd}_WARP+orig blip_warp.r{fwd}_WARP+orig\n",
    "        ! 3dcopy blip_warp_Rev.r{rev}_WARP+orig blip_warp.r{rev}_WARP+orig\n",
    "\n",
    "        ! rm blip_warp_Fwd.r{fwd}+orig* blip_warp_Rev.r{rev}+orig* blip_warp_Fwd.r{fwd}_WARP+orig* blip_warp_Rev.r{rev}_WARP+orig* \n",
    "\n",
    "# for QC check，我们生成一个校正前和矫正后的平均EPI数据来作为distortion correction的效果证明\n",
    "! 3dMean -prefix blip_pre_fwd.epi_mean.nii.gz rm.blip.med.masked.fwd.r*\n",
    "! 3dMean -prefix blip_pre_rev.epi_mean.nii.gz rm.blip.med.masked.rev.r*\n",
    "! 3dMean -prefix blip_post_fwd.epi_mean.nii.gz rm.blip.med.masked.fwd.post.r*\n",
    "! 3dMean -prefix blip_post_rev.epi_mean.nii.gz rm.blip.med.masked.rev.post.r*\n",
    "\n",
    "# remove redundent file\n",
    "! rm rm*\n",
    "\n",
    "\n",
    "files=files[:-3]\n",
    "nRuns = len(files)\n",
    "runstr=runstr[:-3]\n",
    "for run in runstr:\n",
    "    ! 3dNwarpApply -quintic -nwarp blip_warp.r{run}_WARP+orig      \\\n",
    "            -source pb02.{subj}.r{run}.tshift+orig         \\\n",
    "            -prefix pb03.{subj}.r{run}.blip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 手动检查 1\n",
    "   \n",
    "    这四个文件也记录了对侧矫正的效果，只要有矫正效果，没有什么大问题即可。\n",
    "  \n",
    "   * blip_pre_fwd.epi_mean.nii.gz\n",
    "   * blip_pre_rev.epi_mean.nii.gz\n",
    "   * blip_post_fwd.epi_mean.nii.gz\n",
    "   * blip_post_rev.epi_mean.nii.gz  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================= volreg =================================\n",
    "base = 'vr_base_min_outlier+orig' #在前面生成\n",
    "\n",
    "# align each dset to base volume, then we separate whether we want to further align epi to anat\n",
    "for run in runstr:\n",
    "    # register each volume to the base image\n",
    "    ! 3dvolreg -verbose -zpad 1 -base {base} \\\n",
    "             -1Dfile dfile.r{run}.1D \\\n",
    "             -cubic \\\n",
    "             -1Dmatrix_save mat.r{run}.vr.aff12.1D \\\n",
    "             -prefix rm.epi.nomask.r{run} pb03.{subj}.r{run}.blip+orig\n",
    "\n",
    "    # create an all-1 dataset to mask the extents of the warp\n",
    "    ! 3dcalc -overwrite -a pb03.{subj}.r{run}.blip+orig -expr 1 -prefix rm.epi.all1\n",
    "\n",
    "    # warp the all-1 dataset for extents masking\n",
    "    ! 3dAllineate -base {base} \\\n",
    "                -input rm.epi.all1+orig \\\n",
    "                -1Dmatrix_apply mat.r{run}.vr.aff12.1D \\\n",
    "                -final NN -quiet \\\n",
    "                -prefix rm.epi.1.r{run}\n",
    "\n",
    "    # make an extents intersection mask of this run across time domain\n",
    "    # this makes a mask that all volumes in this run have valid numbers\n",
    "    ! 3dTstat -min -prefix rm.epi.min.r{run} rm.epi.1.r{run}+orig\n",
    "\n",
    "# --------------- deal with motion parameter -------------------\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# we take dmeaned motion (6), demean motion derivative (6) and their squares (12)\n",
    "# 合并 motion params\n",
    "! cat dfile.r*.1D > dfile_rall.1D\n",
    "# 计算去均值的motion parameters (for use in regression)\n",
    "! 1d_tool.py -infile dfile_rall.1D -set_nruns {nRuns} -demean -write motion_demean.1D\n",
    "# 计算一阶导数 (just to have)\n",
    "! 1d_tool.py -infile dfile_rall.1D -set_nruns {nRuns} -derivative -demean -write motion_deriv.1D\n",
    "# calculate the square of demean and derivative of motion parameters (just to have)\n",
    "# for resting preproc, we usually have 24 motion regressor (6motion+6deriv+12 their square)\n",
    "np.savetxt('motion_demeansq.1D', np.loadtxt('motion_demean.1D')**2)\n",
    "np.savetxt('motion_derivsq.1D', np.loadtxt('motion_deriv.1D')**2)\n",
    "# create censor file motion_${subj}_censor.1D, for censoring motion\n",
    "! 1d_tool.py -infile dfile_rall.1D -set_nruns {nRuns} \\\n",
    "   -show_censor_count -censor_prev_TR \\\n",
    "   -censor_motion {motion_censor} motion_{subj}\n",
    "\n",
    "# Estimate the motion parameter after motion correction, we can check the\n",
    "# effects of MC\n",
    "! mkdir mc\n",
    "for run in runstr:\n",
    "    ! 3dvolreg -verbose -zpad 1 -base {base} \\\n",
    "             -1Dfile dfile.r{run}_pos.1D \\\n",
    "             rm.epi.nomask.r{run}+orig\n",
    "    ! rm volreg+orig*\n",
    "# make a single file of motion params\n",
    "! cat dfile.r*_pos.1D > dfile_rall_pos.1D\n",
    "\n",
    "# make figure pre mc\n",
    "dfile_pre = np.loadtxt('dfile_rall.1D')\n",
    "plot(range(dfile_pre.shape[0]), dfile_pre[:,:3], color=['C0','C1','C2'], label=['roll(IS)','pitch(RL)','yaw(AP)'])\n",
    "plt.legend();plt.xlabel('time points');plt.ylabel('mm');\n",
    "plt.savefig('rots_pre.pdf');plt.close('all')\n",
    "plot(range(dfile_pre.shape[0]), dfile_pre[:,3:], color=['C3','C4','C5'], label=['dS','dL','dP'])\n",
    "plt.legend();plt.xlabel('time points (TR)');plt.ylabel('mm');\n",
    "plt.savefig('tran_pre.pdf');plt.close('all')\n",
    "# make figure pos mc\n",
    "dfile_pos = np.loadtxt('dfile_rall_pos.1D')\n",
    "plot(range(dfile_pos.shape[0]), dfile_pos[:,:3], color=['C0','C1','C2'], label=['roll(IS)','pitch(RL)','yaw(AP)'])\n",
    "plt.legend();plt.xlabel('time points');plt.ylabel('mm');\n",
    "plt.savefig('rots_pos.pdf');plt.close('all')\n",
    "plot(range(dfile_pos.shape[0]), dfile_pos[:,3:], color=['C3','C4','C5'], label=['dS','dL','dP'])\n",
    "plt.legend();plt.xlabel('time points (TR)');plt.ylabel('mm');\n",
    "plt.savefig('tran_pos.pdf');plt.close('all')\n",
    "# move file to directory\n",
    "! mv rots*.pdf tran*.pdf dfile.r*_pos.1D dfile_r*_pos.1D mc/\n",
    "\n",
    "# note TRs that were not censored, note ktrs here is a str\n",
    "ktrs = unix_wrapper(f'1d_tool.py -infile motion_{subj}_censor.1D \\\n",
    "                       -show_trs_uncensored encoded', wantreturn=True, verbose=0)\n",
    "\n",
    "# ----------------------------------------\n",
    "# create the extents mask: mask_epi_extents+orig and apply the task\n",
    "# (this is a mask of voxels that have valid data at every TR,\n",
    "# there might be some pixel out of extents during mc)\n",
    "! 3dMean -datum short -prefix rm.epi.mean rm.epi.min.r*.HEAD\n",
    "! 3dcalc -a rm.epi.mean+orig -expr \"step(a-0.999)\" -prefix mask_epi_extents\n",
    "# and apply the extents mask to the EPI data\n",
    "# (delete any time series with missing data)\n",
    "for run in runstr:\n",
    "    ! 3dcalc -a rm.epi.nomask.r{run}+orig -b mask_epi_extents+orig \\\n",
    "           -expr \"a*b\" -prefix pb04.{subj}.r{run}.volreg\n",
    "! rm -f rm.*  # rm.epi.nomask are big files, remove them\n",
    "! rm -f {base}* \n",
    "\n",
    "# calculate a mean epi volume for next step anat epi registration\n",
    "! 3dMean -prefix rm.epi_mean.nii.gz pb04.{subj}.r*.volreg+orig.HEAD\n",
    "! 3dTstat -prefix epi_mean.nii.gz rm.epi_mean.nii.gz\n",
    "! rm rm* mask_epi_extents+orig*\n",
    "\n",
    "# 删掉上一步distortion correction的数据，节省空间\n",
    "! rm pb03*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 手动检查 2\n",
    "  \n",
    "  打开mc/中的四个pdf，检查校正前后的头动情况  \n",
    "  tran_pre不超过±3mm，tran_pos数量级大概是$10^{-2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================= anat2epi =================================\n",
    "# 首先把用来配准的epi像make a copy\n",
    "! 3dcopy epi_mean.nii.gz epi_mean_tmp.nii.gz\n",
    "\n",
    "# 关键步骤。我们是把结构像配准到功能像，但是我们得到的转换矩阵是从相反的，功能像到结构像，这个矩阵可以后面用来转化epi数据\n",
    "! align_epi_anat.py -anat2epi \\\n",
    "    -anat {t1ss} -anat_has_skull no \\\n",
    "    -suffix _al_junk \\\n",
    "    -epi epi_mean_tmp.nii.gz -epi_base 0 \\\n",
    "    -epi_strip 3dAutomask -giant_move \\\n",
    "    -volreg off -tshift off\n",
    "\n",
    "# 生成nifti文件，方便我们在fsleyes上面查看配准效果\n",
    "! 3dcopy {t1ss.pstem}_al_junk+orig {t1ss.pstem}_al_junk.nii.gz\n",
    "\n",
    "# note that we align anat 2 epi, however, this xfm is from epi space to anat space\n",
    "# note that this xfm is compatible with LPS+ space, which is the default space in AFNI\n",
    "! mv {t1ss.pstem}_al_junk_mat.aff12.1D mat.anat2epi.aff12.1D\n",
    "\n",
    "#######去头皮后的结构像就是t1ss({subj}_SurfVol_SS.nii), 不需要再生成\n",
    "# create an skull-striped anat_final dataset, aligned with stats\n",
    "#! 3dcopy {t1ss.pstem}_ns+orig anat_final.{subj}.nii.gz\n",
    "#! rm {t1ss.pstem}_ns+orig*\n",
    "! 3dcopy {t1ss} anat_final.{subj}.nii.gz\n",
    "########\n",
    "\n",
    "# rewrite the name of aligned anat\n",
    "! 3dcopy {t1ss.pstem}_al_junk+orig anat2epi.{subj}.nii.gz\n",
    "! rm {t1ss.pstem}_al_junk+orig*\n",
    "\n",
    "# Invert xfm\n",
    "! cat_matvec -ONELINE mat.anat2epi.aff12.1D -I > mat.epi2anat.aff12.1D\n",
    "\n",
    "# warp the volreg base EPI dataset back to anat to make a final version\n",
    "! 3dAllineate -base anat_final.{subj}.nii.gz \\\n",
    "            -input epi_mean.nii.gz \\\n",
    "            -1Dmatrix_apply mat.epi2anat.aff12.1D \\\n",
    "            -prefix epi2anat.{subj}.nii.gz\n",
    "\n",
    "# Record final registration costs\n",
    "! 3dAllineate -base epi2anat.{subj}.nii.gz -allcostX -input anat_final.{subj}.nii.gz > out.allcostX.txt\n",
    "\n",
    "# Take the snapshots to show the quality of alignment\n",
    "! @snapshot_volreg epi2anat.{subj}.nii.gz anat_final.{subj}.nii.gz\n",
    "! @snapshot_volreg anat_final.{subj}.nii.gz epi2anat.{subj}.nii.gz\n",
    "! @snapshot_volreg anat2epi.{subj}.nii.gz epi_mean.nii.gz\n",
    "! @snapshot_volreg epi_mean.nii.gz anat2epi.{subj}.nii.gz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 手动检查 3\n",
    "   \n",
    "   仔细检查配准结果,检查两者是否一致。\n",
    "\n",
    "   * Underlay: epi_mean_tmp+orig  \n",
    "   * Overlay: subj_SurfVol_al_junk+orig  \n",
    "\n",
    "   如果不匹配，需要重新进行anat2epi的过程。开始之前，需要先删除上面产生的文件: \n",
    "      ```\n",
    "      ! rm {sub}_SurfVol_al* {subj}_SurfVol_ns*\n",
    "      ```\n",
    "   确认配准没有问题之后，进行下一步操作\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================= epi to individual anat =================================\n",
    "# resolution=2.5  # 改到最开始的参数设置\n",
    "# ======== Transform epi to match anat, add by RZ ===============\n",
    "# In this step we need to concatenate Distortion(opt)+motion+affine transformations\n",
    "# align each dset to base volume, then we separate whether we want to further align epi to anat\n",
    "for run in runstr:\n",
    "    # concatenate MC+aff transforms\n",
    "    ! cat_matvec -ONELINE mat.anat2epi.aff12.1D -I mat.r{run}.vr.aff12.1D > mat.r{run}.warp.aff12.1D\n",
    "\n",
    "    # we apply distortion correction + motion correction + anat2epi transformation\n",
    "    cmd = f'3dNwarpApply -quintic -nwarp \"mat.r{run}.warp.aff12.1D blip_warp.r{run}_WARP+orig\" \\\n",
    "            -master {t1ss} -dxyz {resolution} \\\n",
    "            -source pb02.{subj}.r{run}.tshift+orig         \\\n",
    "            -prefix rm.epi.nomask.r{run}'\n",
    "    unix_wrapper(cmd)\n",
    "\n",
    "    # create an all-1 dataset to mask the extents of the warp\n",
    "    ! 3dcalc -overwrite -a pb02.{subj}.r{run}.tshift+orig -expr 1 -prefix rm.epi.all1\n",
    "\n",
    "    # we apply distortion correction + motion correction + anat2epi transformation\n",
    "    cmd = f'3dNwarpApply -quintic -nwarp \"mat.r{run}.warp.aff12.1D blip_warp.r{run}_WARP+orig\" \\\n",
    "            -master {t1ss} -dxyz {resolution} \\\n",
    "            -ainterp NN -quiet \\\n",
    "            -source rm.epi.all1+orig \\\n",
    "            -prefix rm.epi.1.r{run}'\n",
    "    unix_wrapper(cmd)\n",
    "\n",
    "    # make an extents intersection mask of this run across time domain\n",
    "    # this makes a mask that all volumes in this run have valid numbers\n",
    "    ! 3dTstat -min -prefix rm.epi.min.r{run} rm.epi.1.r{run}+orig\n",
    "    # below file is big, should be removed\n",
    "    ! rm rm.epi.1.r{run}+orig*\n",
    "\n",
    "# ----------------------------------------\n",
    "# create the extents mask: mask_epi_extents+orig\n",
    "# (this is a mask of voxels that have valid data at every TR,\n",
    "# there might be some pixel out of extents during mc)\n",
    "! 3dMean -datum short -prefix rm.epi.mean rm.epi.min.r*.HEAD\n",
    "# and apply the extents mask to the EPI data\n",
    "! 3dcalc -a rm.epi.mean+orig -expr \"step(a-0.999)\" -prefix mask_epi_extents\n",
    "\n",
    "# 去掉mask之外的voxel的数据\n",
    "for run in runstr:\n",
    "    ! 3dcalc -a rm.epi.nomask.r{run}+orig -b mask_epi_extents+orig \\\n",
    "           -expr \"a*b\" -prefix pb05.{subj}.r{run}.al2anat\n",
    "    # save to nifti format seems to reduce file size\n",
    "\n",
    "# rm.epi.nomask are big files, remove them\n",
    "! rm rm.*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ================================= epi volume to surface =================================\n",
    "surface_dir = FREESURFER_HOME+f'/subjects/{subj}/SUMA'\n",
    "# map volume data to the surface of each hemisphere\n",
    "for hemi in ['lh', 'rh']:\n",
    "    for  run in runstr:\n",
    "        ! 3dVol2Surf -spec {surface_dir}/std.141.{subj}_{hemi}.spec   \\\n",
    "                   -sv {subj}_SurfVol_2std.nii           \\\n",
    "                   -surf_A smoothwm                            \\\n",
    "                   -surf_B pial                                \\\n",
    "                   -f_index nodes                              \\\n",
    "                   -f_steps 10                                 \\\n",
    "                   -map_func ave                               \\\n",
    "                   -oob_value 0                                \\\n",
    "                   -grid_parent pb05.{subj}.r{run}.al2anat+orig   \\\n",
    "                   -out_niml pb05.{subj}.{hemi}.r{run}.surf.niml.dset\n",
    "\n",
    "\n",
    "\n",
    "# ================================= epi to MNI anat =================================\n",
    "# ======== Transform epi to match anat, add by RZ ===============\n",
    "# In this step we need to concatenate Distortion(opt)+motion+affine transformations\n",
    "# align each dset to base volume, then we separate whether we want to further align epi to anat\n",
    "for run in runstr:\n",
    "\n",
    "    # we apply distortion correction + motion correction + anat2epi + nonlinear warp to MNI transformation\n",
    "    # 注意我们这里是相反的顺序来concatenate的\n",
    "    cmd = f'3dNwarpApply -quintic -nwarp \"anatQQ.{subj}_WARP.nii anatQQ.{subj}.aff12.1D mat.r{run}.warp.aff12.1D blip_warp.r{run}_WARP+orig\" \\\n",
    "            -master MNI152_2009_template_SSW.nii.gz \\\n",
    "            -dxyz {resolution} \\\n",
    "            -source pb02.{subj}.r{run}.tshift+orig \\\n",
    "            -prefix rm.epi.nomask.r{run}'\n",
    "    unix_wrapper(cmd)\n",
    "\n",
    "    # create an all-1 dataset to mask the extents of the warp\n",
    "    ! 3dcalc -overwrite -a pb02.{subj}.r{run}.tshift+orig -expr 1 -prefix rm.epi.all1\n",
    "\n",
    "    # we apply distortion correction + motion correction + anat2epi transformation\n",
    "    cmd = f'3dNwarpApply -quintic -nwarp \"anatQQ.{subj}_WARP.nii anatQQ.{subj}.aff12.1D mat.r{run}.warp.aff12.1D blip_warp.r{run}_WARP+orig\" \\\n",
    "            -master MNI152_2009_template_SSW.nii.gz \\\n",
    "            -dxyz {resolution} \\\n",
    "            -source rm.epi.all1+orig         \\\n",
    "            -ainterp NN -quiet \\\n",
    "            -prefix rm.epi.1.r{run}'\n",
    "    unix_wrapper(cmd)\n",
    "\n",
    "    # make an extents intersection mask of this run across time domain\n",
    "    # this makes a mask that all volumes in this run have valid numbers\n",
    "    ! 3dTstat -min -prefix rm.epi.min.r{run} rm.epi.1.r{run}+tlrc\n",
    "    # below file is big, should be removed\n",
    "    ! rm rm.epi.1.r{run}+tlrc*      \n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# create the extents mask: mask_epi_extents+orig\n",
    "# (this is a mask of voxels that have valid data at every TR,\n",
    "# there might be some pixel out of extents during mc)\n",
    "! 3dMean -datum short -prefix rm.epi.mean rm.epi.min.r*.HEAD\n",
    "! 3dcalc -a rm.epi.mean+tlrc -expr \"step(a-0.999)\" -prefix mask_epi_2mni_extents\n",
    "\n",
    "# 去掉mask之外的voxel的数据\n",
    "for run in runstr:\n",
    "    ! 3dcalc -a rm.epi.nomask.r{run}+tlrc -b mask_epi_2mni_extents+tlrc \\\n",
    "           -expr \"a*b\" -prefix pb06.{subj}.r{run}.al2mni\n",
    "    # save to nifti format seems to reduce file size\n",
    "\n",
    "# rm.epi.nomask are big files, remove them\n",
    "! rm rm.*\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# smooth\n",
    "# 补充步骤，用于进行smooth操作，  2022.7.3添加\n",
    "# 目的是对上一步step8所生成的pb06进行smooth   生成pb06s\n",
    "# 再对上上一步step7所生成的pb05***surf.niml文件进行smooth  生成pb05s*rh  和 pb05s*lh\n",
    "# 再对上上一步step7所生成的pb05.subj.r0*.al2anat+orig文件进行smooth  生成pb05s*.subj.r0*.blur+al2anat+orig\n",
    "\n",
    "for run in runstr:\n",
    "    ! 3dmerge -1blur_fwhm 4.0 -doall -prefix pb06s.{subj}.r{run}.blur+al2mni+tlrc \\\n",
    "        pb06.{subj}.r{run}.al2mni+tlrc\n",
    "\n",
    "for run in runstr:\n",
    "    ! 3dmerge -1blur_fwhm 4.0 -doall -prefix pb05s.{subj}.lh.r{run}.blur.surf.niml.dset \\\n",
    "        pb05.{subj}.lh.r{run}.surf.niml.dset\n",
    "\n",
    "for run in runstr:\n",
    "    ! 3dmerge -1blur_fwhm 4.0 -doall -prefix pb05s.{subj}.rh.r{run}.blur.surf.niml.dset \\\n",
    "        pb05.{subj}.rh.r{run}.surf.niml.dset\n",
    "\n",
    "#以下代码可以不用跑\n",
    "for run in runstr:\n",
    "    ! 3dmerge -1blur_fwhm 4.0 -doall -prefix pb05s.{subj}.r{run}.blur+al2anat+orig \\\n",
    "        pb05.{subj}.r{run}.al2anat+orig\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== Mask =================================\n",
    "# Create 'full_mask' dataset (union mask)\n",
    "for run in runstr:\n",
    "    ! 3dAutomask -prefix rm.mask_r{run}.nii.gz pb06.{subj}.r{run}.al2mni+tlrc\n",
    "\n",
    "# 创造一个所有功能像的run合起来的mask\n",
    "! 3dmask_tool -inputs rm.mask_r*.nii.gz -union -prefix full_mask.{subj}.nii.gz\n",
    "! rm rm.mask*\n",
    "\n",
    "# ---- create subject anatomy mask, mask_anat.$subj+orig ----\n",
    "#      (resampled from aligned anat)\n",
    "# 把功能像resample到上面mask的分辨率\n",
    "! 3dresample -master full_mask.{subj}.nii.gz -input \\\n",
    "           MNI152_2009_template_SSW.nii.gz -prefix rm.resam.anat.nii.gz\n",
    "# convert to binary anat mask; fill gaps and holes\n",
    "! 3dmask_tool -dilate_input 5 -5 -fill_holes -input rm.resam.anat.nii.gz \\\n",
    "            -prefix mask_anat.{subj}.nii.gz\n",
    "\n",
    "# 结合功能像和结构像的mask\n",
    "# compute tighter EPI mask by intersecting with anat mask\n",
    "! 3dmask_tool -input full_mask.{subj}.nii.gz mask_anat.{subj}.nii.gz \\\n",
    "            -inter -prefix mask_epi_anat.{subj}.nii.gz\n",
    "# note Dice coefficient of masks, as well\n",
    "! 3ddot -dodice full_mask.{subj}.nii.gz mask_anat.{subj}.nii.gz > out.mask_ae_dice.txt\n",
    "\n",
    "# 删掉多余文件\n",
    "! rm rm*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ====================== scale =================================\n",
    "# 注意！！！这个cell的代码是对pb06以及pb05 进行scale重置 也就是未经smooth的数据\n",
    "# scale each voxel time series to have a mean of 100\n",
    "# (be sure no negatives creep in)\n",
    "# (subject to a range of [0,200])\n",
    "# scale volume data\n",
    "\n",
    "for run in runstr:\n",
    "    ! 3dTstat -prefix rm.mean_r{run} pb06.{subj}.r{run}.al2mni+tlrc\n",
    "    ! 3dcalc -a pb06.{subj}.r{run}.al2mni+tlrc -b rm.mean_r{run}+tlrc \\\n",
    "           -c mask_epi_2mni_extents+tlrc \\\n",
    "           -expr \"c * min(200, a/b*100)*step(a)*step(b)\" \\\n",
    "           -prefix pb07.{subj}.r{run}.scale\n",
    "\n",
    "# combine all datasets into one\n",
    "! 3dTcat -prefix all_runs.{subj}.nii.gz pb07.{subj}.r*.scale+tlrc*\n",
    "# remove redundant file\n",
    "! rm rm.mean*\n",
    "\n",
    "# 再scale surface data\n",
    "for hemi in ['lh', 'rh']:\n",
    "    for run in runstr:\n",
    "       ! 3dTstat -prefix rm.{hemi}.mean_r{run}.niml.dset    \\\n",
    "            pb05.{subj}.{hemi}.r{run}.surf.niml.dset\n",
    "       ! 3dcalc -a pb05.{subj}.{hemi}.r{run}.surf.niml.dset  \\\n",
    "               -b rm.{hemi}.mean_r{run}.niml.dset          \\\n",
    "               -expr 'min(200, a/b*100)*step(a)*step(b)' \\\n",
    "               -prefix pb07.{subj}.{hemi}.r{run}.scale.niml.dset\n",
    "\n",
    "# remove redundant file\n",
    "! rm rm.*mean* \n",
    "\n",
    "\n",
    "# 注意！！！这个cell的代码是对pb06s 以及pb05s 进行scale重置 也就是经过了smooth的数据\n",
    "# 生成pb07s*.scale  \n",
    "# 这个文件被整合成all_runs_with_smooth\n",
    "# 生成pb07s*.scale.niml.dset\n",
    "\n",
    "# scale volume data\n",
    "for run in runstr:\n",
    "    ! 3dTstat -prefix rm.mean_r{run} pb06s.{subj}.r{run}.blur+al2mni+tlrc\n",
    "    ! 3dcalc -a pb06s.{subj}.r{run}.blur+al2mni+tlrc -b rm.mean_r{run}+tlrc \\\n",
    "           -c mask_epi_2mni_extents+tlrc \\\n",
    "           -expr \"c * min(200, a/b*100)*step(a)*step(b)\" \\\n",
    "           -prefix pb07s.{subj}.r{run}.scale\n",
    "\n",
    "# combine all datasets into one\n",
    "! 3dTcat -prefix all_runs_with_smooth.{subj}.nii.gz pb07s.{subj}.r*.scale+tlrc*\n",
    "# remove redundant file\n",
    "! rm rm.mean*\n",
    "\n",
    "# 再scale surface data\n",
    "for hemi in ['lh', 'rh']:\n",
    "    for run in runstr:\n",
    "       ! 3dTstat -prefix rm.{hemi}.mean_r{run}.niml.dset    \\\n",
    "            pb05s.{subj}.{hemi}.r{run}.blur.surf.niml.dset\n",
    "       ! 3dcalc -a pb05s.{subj}.{hemi}.r{run}.blur.surf.niml.dset  \\\n",
    "               -b rm.{hemi}.mean_r{run}.niml.dset          \\\n",
    "               -expr 'min(200, a/b*100)*step(a)*step(b)' \\\n",
    "               -prefix pb07s.{subj}.{hemi}.r{run}.scale.niml.dset\n",
    "# remove redundant file\n",
    "! rm rm.*mean* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### funcpp03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================ regress =================================\n",
    "# compute de-meaned motion parameters (for use in regression)\n",
    "# in regress (detrend step)\n",
    "\n",
    "# ------------------------------\n",
    "# run the regression analysis. Note that stats results should be written as afni format\n",
    "\n",
    "! 3dDeconvolve -input pb07.{subj}.r*.scale+tlrc.HEAD \\\n",
    "    -mask mask_epi_anat.{subj}.nii.gz \\\n",
    "    -censor motion_{subj}_censor.1D \\\n",
    "    -ortvec motion_demean.1D mot_demean \\\n",
    "    -polort 2 \\\n",
    "    -num_stimts 0 \\\n",
    "    -rout \\\n",
    "    -fout -tout -x1D X.xmat.1D -xjpeg X.jpg \\\n",
    "    -x1D_uncensored X.nocensor.xmat.1D \\\n",
    "    -fitts motpoly.fitts.{subj} \\\n",
    "    -errts motpoly.errts.{subj} \\\n",
    "    -bucket motpoly.stats.{subj}\n",
    "\n",
    "# should add save a script here\n",
    "\n",
    "# -- use 3dTproject to project out regression matrix --\n",
    "! 3dTproject -polort 0 -input pb07.{subj}.r*.scale+tlrc.HEAD \\\n",
    "           -censor motion_{subj}_censor.1D -cenmode ZERO \\\n",
    "           -ort X.nocensor.xmat.1D -prefix motpoly.errts.{subj}.tproject\n",
    "# 3dTproject can also supply '-passband 0.01, 0.08' to band pass time seriest\n",
    "\n",
    "! rm -f motpoly.stats* motpoly.fitts* # remove some large files\n",
    "\n",
    "\n",
    "\n",
    "# --------------------- SNR -----------------------------\n",
    "# create a temporal signal to noise ratio dataset\n",
    "#    signal: if 'scale' block, mean should be 100\n",
    "#    noise : compute standard deviation of errts\n",
    "unix_wrapper(f'3dTstat -mean -prefix rm.signal.all.nii.gz all_runs.{subj}.nii.gz\"[{ktrs}]\"')\n",
    "unix_wrapper(f'3dTstat -stdev -prefix rm.noise.all.nii.gz motpoly.errts.{subj}.tproject+tlrc\"[{ktrs}]\"')\n",
    "! 3dcalc -a rm.signal.all.nii.gz \\\n",
    "       -b rm.noise.all.nii.gz \\\n",
    "       -c full_mask.{subj}.nii.gz \\\n",
    "       -expr \"c*a/b\" -prefix TSNR.{subj}.nii.gz\n",
    "\n",
    "# remove redundant files\n",
    "! rm rm.signal.all* rm.noise.all*\n",
    "! rm motpoly.errts* X*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== auto block: finalize ==========================\n",
    "# Remove temporary files\n",
    "! rm -f rm.* # finally remove some left-over files\n",
    "\n",
    "# We can further remove despike, tshift and volreg data at the end volreg are big\n",
    "! rm -f all_runs*\n",
    "! rm anatQQ* MNI152_2009_template_SSW.nii.gz\n",
    "! rm pb01* pb04*\n",
    "! rm epi_mean_tmp*\n",
    "\n",
    "# organize data\n",
    "\n",
    "\n",
    "# ==================== preprocessing done ==================================\n",
    "# return to previous directory\n",
    "os.chdir(cwd)\n",
    "os.environ['SHELL'] = orig_shell     # switch back to the original shell\n",
    "print(f'\\n=============== Preprocessing started: {start_time} ================\\n')\n",
    "print(f'\\n=============== Preprocessing finished: {gettimestr(\"full\")} ================\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 手动检查"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Distortion Correction**  \n",
    "   \n",
    "    这四个文件也记录了对侧矫正的效果，只要有矫正效果，没有什么大问题即可。\n",
    "  \n",
    "   * blip_pre_fwd.epi_mean.nii.gz\n",
    "   * blip_pre_rev.epi_mean.nii.gz\n",
    "   * blip_post_fwd.epi_mean.nii.gz\n",
    "   * blip_post_rev.epi_mean.nii.gz  \n",
    "\n",
    ">\n",
    "\n",
    "2. **Motion Correction**\n",
    "   \n",
    "   打开mc/中的四个pdf，检查校正前后的头动情况  \n",
    "   tran_pre不超过±3mm，tran_pos数量级大概是$10^{-2}$\n",
    "\n",
    ">\n",
    "\n",
    "3. **anat2epi**\n",
    "   \n",
    "   仔细检查配准结果,检查两者是否一致。\n",
    "\n",
    "   * Underlay: epi_mean_tmp+orig  \n",
    "   * Overlay: subj_SurfVol_al_junk+orig  \n",
    "\n",
    "   如果不匹配，需要重新进行anat2epi的过程。开始之前，需要先删除上面产生的文件: \n",
    "      ```\n",
    "      ! rm {sub}_SurfVol_al* {subj}_SurfVol_ns*\n",
    "      ```\n",
    "   确认配准没有问题之后，进行下一步操作"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
