{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 功能像预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是功能像处理的第一部分, 从前面的预处理, 一直到功能像到结构像的配准"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RZutilpy.system import Path, unix_wrapper, gettimestr, makedirs\n",
    "from RZutilpy.rzio import matchfiles\n",
    "from RZutilpy.figure import plot\n",
    "from RZutilpy.mri import findminoutlier\n",
    "import os\n",
    "\n",
    "# subject name\n",
    "subj = 'CN003'\n",
    "\n",
    "# a list of functional NIFTI files\n",
    "files = matchfiles(f'/home/data/rawdata/20220110_CET_CN003/*epi*.nii')\n",
    "\n",
    "# t1 file\n",
    "t1 = Path(f'/home/software/freesurfer/subjects/{subj}/SUMA/{subj}_SurfVol.nii')\n",
    "t1ss = Path(f'/home/software/freesurfer/subjects/{subj}/mni/anatSS.{subj}.nii')\n",
    "\n",
    "# output directory, if exists, we exit\n",
    "output_dir = Path(f'/home/data/rawdata/20220110_CET_CN003/funcpp/')\n",
    "\n",
    "# number of tr to discard\n",
    "tr_discard = 0  # number of tr to discard\n",
    "\n",
    "# motion censor limit\n",
    "motion_censor = 0.3  # threshold for motion censoring, default:(0.3)\n",
    "\n",
    "# extra option for align_epi_anat.py\n",
    "align_opt = ['-giant_move']\n",
    "\n",
    "fwdfiles = ['01', '03', '05', '07'] # 这里需要手动run的顺序，用来做配对distortion correction\n",
    "revfiles = ['02', '04', '06', '08']\n",
    "\n",
    "# some calculation\n",
    "nRuns = len(files)\n",
    "runstr = [f'{i+1:02d}' for i in range(nRuns)]\n",
    "motion_censor = 0.3 if motion_censor is None else motion_censor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RZutilpy.system import Path, unix_wrapper, gettimestr, makedirs\n",
    "from RZutilpy.rzio import matchfiles\n",
    "from RZutilpy.figure import plot\n",
    "from RZutilpy.mri import findminoutlier\n",
    "import os\n",
    "\n",
    "# subject name\n",
    "subj = 'test1'\n",
    "\n",
    "# a list of functional NIFTI files\n",
    "files = matchfiles(f'/home/data/rawdata/20210824_faceprf_CN001/rawdicom/*ep2d*.nii')\n",
    "\n",
    "# t1 file\n",
    "t1 = Path(f'/home/software/freesurfer/7.3.2/subjects/{subj}/SUMA/{subj}_SurfVol.nii')\n",
    "t1ss = Path(f'/home/software/freesurfer/7.3.2/subjects/{subj}/mni/anatSS.{subj}.nii')\n",
    "\n",
    "# output directory, if exists, we exit\n",
    "output_dir = Path(f'/home/data/rawdata/20210824_faceprf_CN001/funcpp/')\n",
    "\n",
    "# number of tr to discard\n",
    "tr_discard = 0  # number of tr to discard\n",
    "\n",
    "# motion censor limit\n",
    "motion_censor = 0.3  # threshold for motion censoring, default:(0.3)\n",
    "\n",
    "# extra option for align_epi_anat.py\n",
    "align_opt = ['-giant_move']\n",
    "\n",
    "fwdfiles = ['16', '17', '18', '19'] # 这里需要手动run的顺序，用来做配对distortion correction\n",
    "revfiles = ['20']\n",
    "\n",
    "# some calculation\n",
    "nRuns = len(files)\n",
    "runstr = [f'{i+1:02d}' for i in range(nRuns)]\n",
    "motion_censor = 0.3 if motion_censor is None else motion_censor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一部分，我们主要做到以下几件事情\n",
    "1. 把所有的功能像数据先copy到一个<output_dir>文件夹下, 避免修改原始的功能像数据, 然后去掉每个run前面的几个TR <tr_discard>\n",
    "2. 矫正epi的朝向和正中点\n",
    "    其中如果epi和T1是在不同的session采集的，那么可能会有比较大的偏差。需要手动的移动epi的图像到和用来做FreeSurfer的t1像一致\n",
    "3. 到<output_dir> 文件夹下面，找到头动最小的volume，然后把这个作为头动矫正的基准。这一步会检查头动，并且记录一些特别大头动的volume，以头动超过一定的threshold为准"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. 先需要做一些文件检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== deal with some input parameters =======================\n",
    "# Show some diagnostic information\n",
    "# check file exists\n",
    "for i in files:\n",
    "    assert Path(i).exists(), f'{i} does not exist!'\n",
    "\n",
    "t1 = Path(t1)\n",
    "assert t1.exists(), 'T1 file does not exist!'\n",
    "\n",
    "# generate slice timing file\n",
    "if not Path('SliceTiming.txt').exists():\n",
    "    import json \n",
    "    import numpy as np\n",
    "    with open(f'{Path(files[0]).pstem}.json') as f:\n",
    "        jsoninfo = json.load(f)\n",
    "    np.savetxt('SliceTiming.txt', jsoninfo['SliceTiming'])\n",
    "    print('generate SliceTiming.txt!')\n",
    "    del jsoninfo\n",
    "\n",
    "# 整理forward和reverse的文件，如果两者数量不相等，我们自动补齐缺数量\n",
    "if len(fwdfiles)!=len(fwdfiles):\n",
    "    if len(fwdfiles)>len(revfiles):\n",
    "        nPair = len(fwdfiles)\n",
    "        revfiles = revfiles + [revfiles[end]]*(nPair-len(revfiles))\n",
    "    else:\n",
    "        nPair = len(revfiles)\n",
    "        fwdfiles = fwdfiles + [fwdfiles[end]]*(nPair-len(fwdfiles))\n",
    "\n",
    "# print out some diagnoistic\n",
    "print(f'\\nt1 file is: \\n{t1}')\n",
    "print(f'functional files are: \\n')\n",
    "[print(f'{i}') for i in files]\n",
    "print(f'\\nforward files are: {fwdfiles} \\n')\n",
    "print(f'reverse files are: {revfiles} \\n')\n",
    "print(f'\\nslice timing file is: \\nSliceTiming.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. 进一步的设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = gettimestr(\"full\")\n",
    "print(f'\\n=============== Preprocessing started: {start_time} ================\\n')\n",
    "# change shell to tcsh, afni default shell is tcsh\n",
    "orig_shell = os.environ['SHELL']\n",
    "os.environ['SHELL']='/usr/bin/tcsh'\n",
    "cwd = Path.cwd() # record current directory, we will go back\n",
    "\n",
    "# verify that the results directory does not yet exist\n",
    "output_dir = Path(output_dir)\n",
    "assert not output_dir.exists(), f'output dir {output_dir} already exists'\n",
    "makedirs(output_dir)\n",
    "#makedirs((output_dir / 'stimuli'))\n",
    "# enter the results directory (can begin processing data)\n",
    "os.chdir(output_dir)\n",
    "# copy anatomy to results dir\n",
    "! 3dcopy {t1} {t1.pstem}\n",
    "t1 = Path(f'{t1.pstem}+orig')  # switch t1 to the new location\n",
    "\n",
    "# copy nonlinear-warping MNI files to this folder\n",
    "FREESURFER_HOME = os.getenv('FREESURFER_HOME')\n",
    "AFNI_HOME = os.getenv('AFNIDIR')\n",
    "! cp {FREESURFER_HOME}/subjects/{subj}/mni/anatQQ.{subj}_WARP.nii ./\n",
    "! cp {FREESURFER_HOME}/subjects/{subj}/mni/anatQQ.{subj}.aff12.1D ./\n",
    "! cp {AFNI_HOME}/MNI152_2009_template_SSW.nii.gz ./\n",
    "\n",
    "# 利用fslreorient2std把朝向划到和MNI一样\n",
    "for file in files:\n",
    "    ! fslreorient2std {file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. 复制文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "复制文件到<output_dir>, 同时去掉最开始的几个TR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================ auto block: tcat ============================\n",
    "# apply 3dTcat to copy input dsets to results dir,\n",
    "# while might want removing the first TRs\n",
    "for file, run in zip(files, runstr):\n",
    "    cmd=f'3dTcat -prefix pb00.{subj}.r{run}.tcat {file}[{tr_discard}..$]'\n",
    "    unix_wrapper(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================ auto block: tcat ============================\n",
    "# apply 3dTcat to copy input dsets to results dir,\n",
    "# while might want removing the first TRs\n",
    "\n",
    "files = files[-5:]\n",
    "runstr = [f'{i+16:02d}' for i in range(5)]\n",
    "for file, run in zip(files, runstr):\n",
    "    cmd=f'3dTcat -prefix pb00.{subj}.r{run}.tcat {file}[{tr_discard}..$]'\n",
    "    unix_wrapper(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. 移动EPI文件使其和T1中心重合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================auto block: giant_move, added by RZ ===========================\n",
    "for run in runstr:\n",
    "    # 把图像的中点划到统一显示空间的中点\n",
    "    ! 3drefit -deoblique -xorigin cen -yorigin cen -zorigin cen pb00.{subj}.r{run}.tcat+orig\n",
    "    # 然后把function数据和 t1ss文件的重心移动到一致，这样有利于进行配准\n",
    "    ! @Align_Centers -cm -no_cp -base {t1ss} -dset pb00.{subj}.r{run}.tcat+orig\n",
    "\n",
    "! rm *_shft.1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Step 5. 同时找到outlier最小的一个volume作为后面motion correction的base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findminoutlier(f'pb00.{subj}.r*.tcat+orig.HEAD', output_dir)\n",
    "# this part will generate several files\n",
    "#   out.pre_ss_warn.txt: warning for pre-steady state in the first TRs, consider change tr_discard\n",
    "#   outcont.r**.1D: fraction of outlier in each volume\n",
    "#   outcount_rall.1D concatenate fraction of outlier\n",
    "#   out.min_outlier.txt  tells you which run, which TR is min_outlier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.5 (tags/v3.7.5:5c02a39a0b, Oct 15 2019, 00:11:34) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43945f80469130c119fb960c4295ae331e7fb51022383025e24ae21a08d5f82b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
