{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 功能像预处理"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是功能像处理的第一部分, 从前面的预处理, 一直到功能像到结构像的配准"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RZutilpy.system import Path, unix_wrapper, gettimestr, makedirs\n",
    "from RZutilpy.rzio import matchfiles\n",
    "from RZutilpy.mri import findminoutlier\n",
    "from RZutilpy.figure import plot\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ========================== Set parameter ============================\n",
    "# subject, session, run\n",
    "subj = 'CN049'\n",
    "session = '20240305_CN049_CLearn/'\n",
    "runlist = ['301','401','601','701','501']\n",
    "# =====================================================================\n",
    "\n",
    "\n",
    "foldpath = '/home/data/rawdata/facePRF/'+subj+'_faceprf/'+session\n",
    "os.chdir(foldpath+'rawdata/')\n",
    "\n",
    "# a list of functional NIFTI files\n",
    "files = []\n",
    "for r in runlist:\n",
    "    files.append(matchfiles(foldpath+'rawdata/'+'*_'+r+'_task*.nii'))\n",
    "\n",
    "# t1 file\n",
    "t1 = Path(f'/home/software/freesurfer/7.3.2/subjects/{subj}/SUMA/{subj}_SurfVol.nii')\n",
    "t1ssmask = Path(f'/home/data/rawdata/facePRF/{subj}_faceprf/20230607_CN040_session0/anatpp/T1_SSMask.nii')\n",
    "t1ss = subj+'_SurfVol_SS.nii'\n",
    "\n",
    "# output directory, if exists, we exit\n",
    "output_dir = Path(foldpath+'/funcpp/')\n",
    "\n",
    "# number of tr to discard\n",
    "tr_discard = 0  # number of tr to discard\n",
    "\n",
    "# motion censor limit\n",
    "motion_censor = 0.3  # threshold for motion censoring, default:(0.3)\n",
    "\n",
    "# extra option for align_epi_anat.py\n",
    "align_opt = ['-giant_move']\n",
    "\n",
    "# epi2anat(individual)\n",
    "resolution = 2.5\n",
    "\n",
    "# grid at each axies of {subj}.SurfVol.nii\n",
    "grid_RL = 256\n",
    "grid_AP = 256\n",
    "grid_IS = 256\n",
    "\n",
    "# some calculation\n",
    "fwdnum = 4\n",
    "revnum = 1\n",
    "nRuns = len(files)\n",
    "runstr = [f'{i:02d}AP' for i in range(1,fwdnum+1)] + [f'{i:03d}PA' for i in range(1,revnum+1)]\n",
    "motion_censor = 0.3 if motion_censor is None else motion_censor\n",
    "\n",
    "fwdfiles = ['01AP', '02AP','03AP', '04AP'] # 这里需要手动run的顺序，用来做配对distortion correction\n",
    "revfiles = ['001PA','001PA','001PA', '001PA']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一部分，我们主要做到以下几件事情\n",
    "1. 把所有的功能像数据先copy到一个<output_dir>文件夹下, 避免修改原始的功能像数据, 然后去掉每个run前面的几个TR <tr_discard>\n",
    "2. 矫正epi的朝向和正中点\n",
    "    其中如果epi和T1是在不同的session采集的，那么可能会有比较大的偏差。需要手动的移动epi的图像到和用来做FreeSurfer的t1像一致\n",
    "3. 到<output_dir> 文件夹下面，找到头动最小的volume，然后把这个作为头动矫正的基准。这一步会检查头动，并且记录一些特别大头动的volume，以头动超过一定的threshold为准"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. 先需要做一些文件检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== deal with some input parameters =======================\n",
    "# Show some diagnostic information\n",
    "# check file exists\n",
    "for i in files:\n",
    "    assert Path(i).exists(), f'{i} does not exist!'\n",
    "\n",
    "t1 = Path(t1)\n",
    "assert t1.exists(), 'T1 file does not exist!'\n",
    "\n",
    "# generate slice timing file\n",
    "if not Path('SliceTiming.txt').exists():\n",
    "    import json \n",
    "    #with open(f'{Path(files[0])}.json') as f:\n",
    "    with open(f'{files[0][:-4]}.json') as f:\n",
    "        jsoninfo = json.load(f)\n",
    "    np.savetxt('SliceTiming.txt', jsoninfo['SliceTiming'])\n",
    "    print('generate SliceTiming.txt!')\n",
    "    del jsoninfo\n",
    "\n",
    "# 整理forward和reverse的文件，如果两者数量不相等，我们自动补齐缺数量\n",
    "if len(fwdfiles)!=len(revfiles):\n",
    "    if len(fwdfiles)>len(revfiles):\n",
    "        nPair = len(fwdfiles)\n",
    "        revfiles = revfiles + [revfiles[-1]]*(nPair-len(revfiles))\n",
    "    else:\n",
    "        nPair = len(revfiles)\n",
    "        fwdfiles = fwdfiles + [fwdfiles[-1]]*(nPair-len(fwdfiles))\n",
    "\n",
    "# print out some diagnoistic\n",
    "print(f'\\nt1 file is: \\n{t1}')\n",
    "print(f'functional files are: \\n')\n",
    "[print(f'{i}') for i in files]\n",
    "print(f'\\nforward files are: {fwdfiles} \\n')\n",
    "print(f'reverse files are: {revfiles} \\n')\n",
    "print(f'\\nslice timing file is: \\nSliceTiming.txt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. 进一步的设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = gettimestr(\"full\")\n",
    "print(f'\\n=============== Preprocessing started: {start_time} ================\\n')\n",
    "# change shell to tcsh, afni default shell is tcsh\n",
    "orig_shell = os.environ['SHELL']\n",
    "os.environ['SHELL']='/usr/bin/tcsh'\n",
    "cwd = Path.cwd() # record current directory, we will go back\n",
    "\n",
    "# verify that the results directory does not yet exist\n",
    "output_dir = Path(output_dir)\n",
    "assert not output_dir.exists(), f'output dir {output_dir} already exists'\n",
    "makedirs(output_dir)\n",
    "#makedirs((output_dir / 'stimuli'))\n",
    "# enter the results directory (can begin processing data)\n",
    "os.chdir(output_dir)\n",
    "# copy anatomy to results dir\n",
    "! 3dcopy {t1} {t1.pstem}\n",
    "t1 = Path(f'{t1.pstem}+orig')  # switch t1 to the new location\n",
    "\n",
    "# copy nonlinear-warping MNI files to this folder\n",
    "FREESURFER_HOME = os.getenv('FREESURFER_HOME')\n",
    "AFNI_HOME = os.getenv('AFNIDIR')\n",
    "! cp {FREESURFER_HOME}/subjects/{subj}/mni/anatQQ.{subj}_WARP.nii ./\n",
    "! cp {FREESURFER_HOME}/subjects/{subj}/mni/anatQQ.{subj}.aff12.1D ./\n",
    "! cp {AFNI_HOME}/MNI152_2009_template_SSW.nii.gz ./\n",
    "! cp {t1ssmask} T1_SSMask.{subj}.nii\n",
    "! 3dcopy {t1} {subj}_SurfVol.nii\n",
    "\n",
    "\n",
    "# 根据T1_SSMask.{subj}.nii得到剥头皮后的T1，但首先要把朝向和grid对齐\n",
    "! 3dresample -orient LPI -prefix {subj}_SurfVol_2std.nii -input {subj}_SurfVol.nii\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "# 利用3dZeropad将mask和T1像的grid对齐，否则无法把mask和T1像相乘：\n",
    "# 例如在这个例子中{subj}_SurfVol.nii是256 x 256 x 256，而T1_SSMask.{subj}.nii是240 x 256 x 256。所以这里在T1_SSMask.{subj}.nii的第一个轴（R-L）修改为256。相当于在左右两侧分别加了8.\n",
    "# 3个轴： -RL -AP -IS，请根据具体情况修改此行代码\n",
    "! 3dZeropad -RL {grid_RL} -prefix T1_SSMask_grid.{subj}.nii  T1_SSMask.{subj}.nii\n",
    "! 3dZeropad -AP {grid_AP} -prefix T1_SSMask_grid.{subj}.nii  T1_SSMask_grid.{subj}.nii -overwrite\n",
    "! 3dZeropad -IS {grid_IS} -prefix T1_SSMask_grid.{subj}.nii  T1_SSMask_grid.{subj}.nii -overwrite\n",
    "#-------------------------------------------------------------\n",
    "\n",
    "! 3dcalc -a {subj}_SurfVol_2std.nii -b T1_SSMask_grid.{subj}.nii -expr 'a*step(b)' -prefix {t1ss}\n",
    "t1ss = Path(t1ss)  # switch t1 to the new location\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. 复制文件"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "复制文件到<output_dir>, 同时去掉最开始的几个TR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================ auto block: tcat ============================\n",
    "# apply 3dTcat to copy input dsets to results dir,\n",
    "# while might want removing the first TRs\n",
    "\n",
    "for file, run in zip(files, runstr):\n",
    "    cmd=f'3dTcat -prefix pb00.{subj}.r{run}.tcat {file}[{tr_discard}..$]'\n",
    "    unix_wrapper(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================reorient =========================\n",
    "# 利用3dresample把朝向划到标准朝向LPI\n",
    "# 需要AP,PA一起做\n",
    "for run in runstr:\n",
    "    ! 3dresample -orient LPI -prefix pb00.{subj}.r{run}.tcat+orig -input pb00.{subj}.r{run}.tcat+orig -overwrite\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. 移动EPI文件使其和T1中心重合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================auto block: giant_move, added by RZ ===========================\n",
    "for run in runstr:\n",
    "    # 把图像的中点划到统一显示空间的中点\n",
    "    ! 3drefit -deoblique -xorigin cen -yorigin cen -zorigin cen pb00.{subj}.r{run}.tcat+orig\n",
    "    # 然后把function数据和 t1ss文件的重心移动到一致，这样有利于进行配准\n",
    "    ! @Align_Centers -cm -no_cp -base {t1ss} -dset pb00.{subj}.r{run}.tcat+orig\n",
    "\n",
    "! rm *_shft.1D\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Step 5. 同时找到outlier最小的一个volume作为后面motion correction的base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findminoutlier(f'pb00.{subj}.r*AP.tcat+orig.HEAD', output_dir)\n",
    "# this part will generate several files\n",
    "#   out.pre_ss_warn.txt: warning for pre-steady state in the first TRs, consider change tr_discard\n",
    "#   outcont.r**.1D: fraction of outlier in each volume\n",
    "#   outcount_rall.1D concatenate fraction of outlier\n",
    "#   out.min_outlier.txt  tells you which run, which TR is min_outlier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43945f80469130c119fb960c4295ae331e7fb51022383025e24ae21a08d5f82b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
